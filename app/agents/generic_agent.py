import openai
from typing import Dict, Any, Optional
from ..models.message import Message, ConversationHistory
from ..utils.logging import AgentLogger
from ..utils.conversation_formatter import (
    format_conversation_for_llm_messages,
    should_include_conversation_history,
)
import time


class GenericAgent:
    """Agent principal pour les questions g√©n√©rales et le petit talk"""

    def __init__(self, openai_client: openai.AsyncOpenAI, model: str = "gpt-3.5-turbo"):
        self.client = openai_client
        self.model = model
        self.logger = AgentLogger("generic_agent")

        self.system_prompt = """Tu es un assistant IA int√©gr√© √† Grist, une plateforme de gestion de donn√©es.

Ton r√¥le est de :
- R√©pondre aux questions g√©n√©rales sur Grist et ses fonctionnalit√©s
- Aider l'utilisateur √† comprendre comment utiliser le widget IA
- Faire du petit talk de mani√®re amicale et professionnelle
- Guider l'utilisateur vers les bonnes questions pour analyser ses donn√©es

Contexte : L'utilisateur travaille avec un document Grist contenant des donn√©es qu'il peut analyser via ce widget IA.

Instructions :
- Sois amical, utile et professionnel
- Sois pr√©cis et d√©taill√© dans tes r√©ponses quand n√©cessaire
- Si l'utilisateur pose une question sur des donn√©es sp√©cifiques, sugg√®re-lui de reformuler pour une analyse de donn√©es
- N'invente jamais de donn√©es ou d'informations sp√©cifiques au document de l'utilisateur

Exemples de r√©ponses appropri√©es :
- Salutations et pr√©sentations
- Explication des capacit√©s du widget
- Conseils sur comment poser des questions d'analyse
- Aide g√©n√©rale sur Grist"""

    async def process_message(self, context) -> str:
        """Traite un message g√©n√©rique ou fallback d'erreur"""
        start_time = time.time()

        self.logger.log_agent_start("generic", context.user_message[:80])

        # V√©rifier si on arrive d'une erreur d'un autre agent
        if context.error:
            return self._handle_error_fallback(context)

        try:
            # Traitement normal pour message g√©n√©rique
            return await self._generate_generic_response(context)
            
        except Exception as e:
            execution_time = time.time() - start_time

            # ü§ñ Log lisible d'erreur IA
            self.logger.log_ai_response(
                model=self.model, success=False, request_id=context.request_id
            )

            self.logger.error(
                f"Erreur lors du traitement g√©n√©rique: {str(e)}",
                request_id=context.request_id,
                execution_time=execution_time,
            )
            return self._get_fallback_response(context.user_message)
    
    def _handle_error_fallback(self, context) -> str:
        """G√®re les fallbacks d'erreurs d'autres agents"""
        
        if context.agent_used == "sql":
            return self._handle_sql_fallback(context.user_message, context.error)
        elif context.agent_used == "architecture":
            return self._handle_architecture_fallback(context.user_message, context.error)
        else:
            return self._handle_generic_error_fallback(context.user_message, context.error)
    
    def _handle_sql_fallback(self, user_message: str, sql_error: str) -> str:
        """Fallback sp√©cifique pour les erreurs SQL"""
        return f"""Je ne peux pas ex√©cuter votre requ√™te sur les donn√©es.

**Probl√®me :** {sql_error}

Vous pouvez essayer de :
‚Ä¢ V√©rifier vos permissions d'acc√®s au document
‚Ä¢ Reformuler votre question diff√©remment
‚Ä¢ Me poser une question g√©n√©rale sur Grist

En attendant, je peux vous aider avec d'autres questions !"""
    
    def _handle_architecture_fallback(self, user_message: str, architecture_error: str) -> str:
        """Fallback sp√©cifique pour les erreurs d'architecture"""
        return f"""Je ne peux pas analyser la structure de vos donn√©es.

**Probl√®me :** {architecture_error}

Vous pouvez essayer de :
‚Ä¢ V√©rifier vos permissions d'acc√®s
‚Ä¢ Reformuler votre question sur la structure des donn√©es
‚Ä¢ Me poser d'autres questions sur Grist

Comment puis-je vous aider autrement ?"""
    
    def _handle_generic_error_fallback(self, user_message: str, error: str) -> str:
        """Fallback g√©n√©rique pour autres erreurs"""
        return f"""Je rencontre une difficult√© technique.

**Probl√®me :** {error}

Pouvez-vous :
‚Ä¢ Reformuler votre question
‚Ä¢ Essayer une approche diff√©rente
‚Ä¢ Me poser une autre question

Je suis l√† pour vous aider avec Grist !"""
    
    async def _generate_generic_response(self, context) -> str:
        """G√©n√®re une r√©ponse g√©n√©rique normale"""
        
        # Construction du contexte conversationnel
        messages = [{"role": "system", "content": self.system_prompt}]

        # Ajout de l'historique de conversation format√© (paires user/assistant compl√®tes)
        if should_include_conversation_history("generic"):
            history_messages = format_conversation_for_llm_messages(
                context.conversation_history, max_pairs=3
            )
            messages.extend(history_messages)

        messages.append({"role": "user", "content": context.user_message})

        # ü§ñ Log lisible de la requ√™te IA
        prompt_text = "\n".join(
            [f"{msg['role']}: {msg['content']}" for msg in messages]
        )
        self.logger.log_ai_request(
            model=self.model,
            messages_count=len(messages),
            max_tokens=800,
            request_id=context.request_id,
            prompt_preview=prompt_text,
        )

        response = await self.client.chat.completions.create(
            model=self.model, messages=messages, max_tokens=800, temperature=0.7
        )

        ai_response = response.choices[0].message.content.strip()

        # ü§ñ Log lisible de la r√©ponse IA
        tokens_used = (
            getattr(response.usage, "total_tokens", None)
            if hasattr(response, "usage")
            else None
        )
        self.logger.log_ai_response(
            model=self.model,
            tokens_used=tokens_used,
            success=True,
            request_id=context.request_id,
            response_preview=ai_response,
        )

        execution_time = time.time() - time.time()
        self.logger.log_agent_response("generic", True, execution_time)

        return ai_response

    def _get_fallback_response(self, user_message: str) -> str:
        """R√©ponse de secours en cas d'erreur"""
        user_lower = user_message.lower()

        if any(
            greeting in user_lower for greeting in ["bonjour", "salut", "hello", "hey"]
        ):
            return "Bonjour ! Je suis votre assistant IA pour Grist. Comment puis-je vous aider aujourd'hui ?"

        elif any(help_word in user_lower for help_word in ["aide", "help", "comment"]):
            return (
                "Je peux vous aider √† analyser vos donn√©es Grist ! "
                "Posez-moi des questions sur vos donn√©es ou demandez-moi de g√©n√©rer des analyses. "
                "Par exemple : 'Montre-moi les tendances de ventes' ou 'Combien d'utilisateurs avons-nous ?'"
            )

        elif any(what_word in user_lower for what_word in ["quoi", "what", "que"]):
            return (
                "Je suis un assistant IA int√©gr√© √† votre document Grist. "
                "Je peux analyser vos donn√©es, g√©n√©rer des requ√™tes SQL, et r√©pondre √† vos questions g√©n√©rales. "
                "Que souhaitez-vous savoir sur vos donn√©es ?"
            )

        else:
            return (
                "D√©sol√©, je rencontre une difficult√© technique temporaire. "
                "Pouvez-vous reformuler votre question ? Je suis l√† pour vous aider avec vos donn√©es Grist !"
            )

    def _detect_data_question(self, message: str) -> bool:
        """D√©tecte si la question concerne des donn√©es sp√©cifiques"""
        data_indicators = [
            "donn√©es",
            "table",
            "colonne",
            "ligne",
            "enregistrement",
            "vente",
            "client",
            "utilisateur",
            "commande",
            "produit",
            "analyse",
            "statistique",
            "tendance",
            "total",
            "moyenne",
            "maximum",
            "minimum",
            "count",
            "sum",
        ]

        message_lower = message.lower()
        return any(indicator in message_lower for indicator in data_indicators)

    def suggest_data_analysis(self, user_message: str) -> str:
        """Sugg√®re comment reformuler pour une analyse de donn√©es"""
        suggestions = [
            "Pour analyser vos donn√©es, essayez des questions comme :",
            "‚Ä¢ 'Montre-moi les ventes du mois dernier'",
            "‚Ä¢ 'Combien d'utilisateurs actifs avons-nous ?'",
            "‚Ä¢ 'Analyse les tendances de nos produits'",
            "‚Ä¢ 'Quelle est la moyenne des commandes par client ?'",
            "",
            "Je peux acc√©der √† vos donn√©es Grist et g√©n√©rer des analyses d√©taill√©es !",
        ]

        return "\n".join(suggestions)
