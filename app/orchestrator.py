"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
AI ORCHESTRATOR V2 - Coordinateur principal avec systÃ¨me de pipeline
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

RÃ”LE:
    L'orchestrateur est le point d'entrÃ©e principal de l'API. Il coordonne
    l'exÃ©cution des agents via un systÃ¨me de pipeline modulaire.

ARCHITECTURE:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  FastAPI Route  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Orchestrator   â”‚ â† Vous Ãªtes ici
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ†’ Router Agent (choisit un plan)
             â”‚
             â”œâ†’ Pipeline Executor (exÃ©cute le plan)
             â”‚   â”‚
             â”‚   â”œâ†’ Generic Agent
             â”‚   â”œâ†’ SQL Agent
             â”‚   â”œâ†’ Analysis Agent
             â”‚   â””â†’ Architecture Agent
             â”‚
             â””â†’ ChatResponse (retournÃ©e Ã  l'utilisateur)

FLUX D'EXÃ‰CUTION:
    1. RÃ©ception ProcessedRequest
    2. Router choisit un ExecutionPlan
    3. Construction du ExecutionContext
    4. PipelineExecutor exÃ©cute les agents sÃ©quentiellement
    5. Chaque agent enrichit le contexte
    6. Retour ChatResponse finale

AVANTAGES DU SYSTÃˆME:
    âœ… Modulaire: Facile d'ajouter/retirer des agents
    âœ… Testable: Chaque composant testÃ© indÃ©pendamment
    âœ… Extensible: Nouveaux plans = quelques lignes
    âœ… Maintenable: Code clair et bien sÃ©parÃ©
    âœ… TraÃ§able: Contexte garde l'historique d'exÃ©cution

EXEMPLE D'UTILISATION:
    >>> orchestrator = AIOrchestrator()
    >>> request = ProcessedRequest(...)
    >>> response = await orchestrator.process_chat_request(request)
    >>> print(response.response)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import openai
import os
import uuid
from typing import Dict, Any
from .models.request import ProcessedRequest, ChatResponse
from .models.message import ConversationHistory
from .utils.logging import AgentLogger
from .config.history_config import HistoryConfig

# Agents
from .agents.router_agent import RouterAgent
from .agents.generic_agent import GenericAgent
from .agents.sql_agent import SQLAgent
from .agents.analysis_agent import AnalysisAgent
from .agents.architecture_agent import DataArchitectureAgent

# Pipeline
from .pipeline.context import ExecutionContext
from .pipeline.executor import PipelineExecutor
from .pipeline.plans import AgentType

# Grist
from .grist.schema_fetcher import GristSchemaFetcher
from .grist.sql_runner import GristSQLRunner
from .grist.sample_fetcher import GristSampleFetcher


class AIOrchestrator:
    """
    Orchestrateur principal gÃ©rant le pipeline d'agents.

    ResponsabilitÃ©s:
        1. Initialiser tous les agents nÃ©cessaires
        2. Recevoir les requÃªtes utilisateur
        3. Coordonner le router et le pipeline executor
        4. GÃ©rer les erreurs globales
        5. Retourner les rÃ©ponses formatÃ©es

    Attributes:
        router: Agent de routing (choix du plan)
        executor: ExÃ©cuteur de pipeline
        agents: Dictionnaire des agents disponibles
        openai_client: Client OpenAI partagÃ©
        logger: Logger pour traÃ§abilitÃ©
    """

    def __init__(self):
        """
        Initialise l'orchestrateur et tous ses composants.

        Configuration depuis variables d'environnement:
            - OPENAI_API_KEY: ClÃ© API OpenAI (obligatoire)
            - OPENAI_API_BASE: URL de base custom (optionnel)
            - DEFAULT_MODEL: ModÃ¨le par dÃ©faut (dÃ©faut: mistral-small)
            - ANALYSIS_MODEL: ModÃ¨le pour analyses (dÃ©faut: mistral-small)
        """
        self.logger = AgentLogger("orchestrator")

        # Configuration OpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        api_base = os.getenv("OPENAI_API_BASE", "https://api.olympia.bhub.cloud/v1")

        if not api_key:
            raise ValueError("OPENAI_API_KEY manquante")

        self.openai_client = openai.AsyncOpenAI(api_key=api_key, base_url=api_base)

        # ModÃ¨les
        self.default_model = os.getenv("DEFAULT_MODEL", "mistral-small")
        self.analysis_model = os.getenv("ANALYSIS_MODEL", "mistral-small")

        # Configuration de l'historique conversationnel
        self.history_config = HistoryConfig.from_env()
        self.logger.info(
            "Configuration d'historique chargÃ©e",
            enabled=self.history_config.enabled,
            max_messages=self.history_config.max_messages,
        )

        # Initialisation des agents
        self._initialize_agents()

        # Statistiques d'utilisation
        self.stats = {
            "total_requests": 0,
            "plan_usage": {"generic": 0, "data_query": 0, "architecture_review": 0},
            "errors": 0,
        }

        self.logger.info(
            "âœ… Orchestrateur initialisÃ© avec succÃ¨s",
            default_model=self.default_model,
            analysis_model=self.analysis_model,
        )

    def _initialize_agents(self):
        """
        Initialise tous les agents du systÃ¨me.

        Cette mÃ©thode crÃ©e:
            - Router Agent (choix de plan)
            - Generic Agent (conversation)
            - SQL Agent (requÃªtes donnÃ©es)
            - Analysis Agent (analyse rÃ©sultats)
            - Architecture Agent (conseil structure)
            - Pipeline Executor (orchestration)
        """
        # Router
        self.router = RouterAgent(self.openai_client, model=self.default_model)

        # Agents mÃ©tier
        self.generic_agent = GenericAgent(self.openai_client, model=self.default_model)

        self.analysis_agent = AnalysisAgent(
            self.openai_client, model=self.analysis_model
        )

        # Agents nÃ©cessitant Grist (crÃ©Ã©s Ã  la demande avec clÃ© API)
        # SQL Agent et Architecture Agent seront crÃ©Ã©s dynamiquement

        # Mapping pour le pipeline executor
        self.base_agents = {
            AgentType.GENERIC: self.generic_agent,
            AgentType.ANALYSIS: self.analysis_agent,
            # SQL et ARCHITECTURE seront ajoutÃ©s dynamiquement
        }

    def _create_agents_with_grist_key(self, grist_api_key: str) -> Dict[AgentType, Any]:
        """
        CrÃ©e les agents nÃ©cessitant une clÃ© API Grist.

        Args:
            grist_api_key: ClÃ© API Grist

        Returns:
            Dictionnaire complet des agents (base + Grist)
        """
        # Initialiser les utilitaires Grist
        schema_fetcher = GristSchemaFetcher(grist_api_key)
        sql_runner = GristSQLRunner(grist_api_key)
        sample_fetcher = GristSampleFetcher()

        # CrÃ©er les agents Grist
        sql_agent = SQLAgent(
            self.openai_client,
            schema_fetcher,
            sql_runner,
            sample_fetcher,
            model=self.default_model,
        )

        architecture_agent = DataArchitectureAgent(
            self.openai_client,
            schema_fetcher,
            sample_fetcher,
            model=self.analysis_model,
        )

        # Merger avec les agents de base
        all_agents = {**self.base_agents}
        all_agents[AgentType.SQL] = sql_agent
        all_agents[AgentType.ARCHITECTURE] = architecture_agent

        return all_agents

    async def process_chat_request(self, request: ProcessedRequest) -> ChatResponse:
        """
        Traite une requÃªte chat complÃ¨te via le pipeline d'agents.

        C'est la mÃ©thode principale appelÃ©e par l'API FastAPI.

        Args:
            request: RequÃªte traitÃ©e contenant:
                - document_id: ID du document Grist
                - messages: Historique de conversation
                - grist_api_key: ClÃ© API Grist
                - execution_mode: Mode d'exÃ©cution (prod/test)

        Returns:
            ChatResponse avec:
                - response: Texte de rÃ©ponse
                - agent_used: Agent ayant gÃ©nÃ©rÃ© la rÃ©ponse
                - sql_query: RequÃªte SQL Ã©ventuelle
                - data_analyzed: Flag d'analyse de donnÃ©es
                - error: Message d'erreur Ã©ventuel

        Exemple:
            >>> request = ProcessedRequest(document_id="doc-123", ...)
            >>> response = await orchestrator.process_chat_request(request)
            >>> print(response.response)
            "Voici vos 10 derniÃ¨res ventes..."
        """
        request_id = str(uuid.uuid4())
        self.stats["total_requests"] += 1

        self.logger.info(
            "ğŸš€ Nouvelle requÃªte de chat",
            request_id=request_id,
            document_id=request.document_id,
            messages_count=len(request.messages),
        )

        try:
            # 1. Extraire le message utilisateur
            conversation_history = ConversationHistory(messages=request.messages)
            user_message = conversation_history.get_last_user_message()

            if not user_message:
                return ChatResponse(
                    response="Aucun message utilisateur trouvÃ© dans la requÃªte.",
                    agent_used="orchestrator",
                    error="No user message",
                )

            # 2. Router â†’ Choisir le plan d'exÃ©cution
            # CrÃ©er un historique filtrÃ© pour le router selon la config
            from .config.history_config import get_agent_config, ConfigAgentType

            router_config = get_agent_config(
                self.history_config, ConfigAgentType.ROUTER
            )
            filtered_messages = router_config.filter_history(
                conversation_history, exclude_last=True
            )
            filtered_history = ConversationHistory(messages=filtered_messages)

            plan = await self.router.route_to_plan(
                user_message.content, filtered_history, request_id
            )

            self.logger.info(
                f"ğŸ“‹ Plan sÃ©lectionnÃ©: {plan.name}",
                request_id=request_id,
                agents=str([a.value for a in plan.agents]),
            )

            # Mettre Ã  jour les stats
            self.stats["plan_usage"][plan.name] += 1

            # 3. CrÃ©er le contexte d'exÃ©cution
            context = ExecutionContext(
                user_message=user_message.content,
                conversation_history=conversation_history,
                document_id=request.document_id,
                grist_api_key=request.grist_api_key,
                request_id=request_id,
                history_config=self.history_config,
            )

            # 4. PrÃ©parer les agents (avec Grist si nÃ©cessaire)
            if plan.requires_api_key:
                if not request.grist_api_key:
                    return ChatResponse(
                        response="Cette opÃ©ration nÃ©cessite une clÃ© API Grist.",
                        agent_used="orchestrator",
                        error="Missing Grist API key",
                    )
                agents = self._create_agents_with_grist_key(request.grist_api_key)
            else:
                agents = self.base_agents

            # 5. CrÃ©er l'executor et exÃ©cuter le pipeline
            executor = PipelineExecutor(agents)
            response = await executor.execute(plan, context)

            self.logger.info(
                "âœ… RequÃªte traitÃ©e avec succÃ¨s",
                request_id=request_id,
                plan_name=plan.name,
                agent_used=response.agent_used,
                has_error=response.error is not None,
            )

            return response

        except Exception as e:
            self.stats["errors"] += 1
            self.logger.error(
                f"âŒ Erreur lors du traitement de la requÃªte: {str(e)}",
                request_id=request_id,
                document_id=request.document_id,
            )

            return ChatResponse(
                response=f"DÃ©solÃ©, une erreur s'est produite: {str(e)}",
                agent_used="orchestrator",
                error=str(e),
            )

    async def health_check(self) -> Dict[str, Any]:
        """
        VÃ©rification de santÃ© du systÃ¨me.

        Teste:
            - Connexion OpenAI
            - DisponibilitÃ© des agents
            - Ã‰tat gÃ©nÃ©ral

        Returns:
            Dictionnaire avec statut de santÃ©

        Exemple:
            >>> health = await orchestrator.health_check()
            >>> print(health["status"])
            "healthy"
        """
        try:
            # Test simple avec OpenAI
            response = await self.openai_client.chat.completions.create(
                model=self.default_model,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5,
            )

            return {
                "status": "healthy",
                "components": {
                    "openai": "ok",
                    "router": "ok",
                    "agents": {"generic": "ok", "analysis": "ok"},
                },
                "stats": self.get_stats(),
            }
        except Exception as e:
            return {"status": "unhealthy", "error": str(e), "stats": self.get_stats()}

    def get_stats(self) -> Dict[str, Any]:
        """
        Retourne les statistiques d'utilisation.

        Returns:
            Dictionnaire avec:
                - total_requests: Nombre total de requÃªtes
                - plan_usage: Utilisation par plan
                - errors: Nombre d'erreurs
                - most_used_plan: Plan le plus utilisÃ©

        Exemple:
            >>> stats = orchestrator.get_stats()
            >>> print(stats["total_requests"])
            142
        """
        # Trouver le plan le plus utilisÃ©
        most_used_plan = max(
            self.stats["plan_usage"].items(), key=lambda x: x[1], default=("none", 0)
        )[0]

        return {**self.stats, "most_used_plan": most_used_plan}
